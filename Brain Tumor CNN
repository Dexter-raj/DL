import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import matplotlib.pyplot as plt
import numpy as np
import os
import random
from sklearn.metrics import classification_report

train_dir = '/home/sanket/DL/1/brain tumour/Training'
test_dir = '/home/sanket/DL/1/brain tumour/Testing'


# Step 2: Data preprocessing
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'  # Multi-class classification
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

# Step 3: Build CNN model
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),
    
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')  # 4 output classes
])

# Step 4: Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Step 5: Train the model
history = model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator
)
test_loss, test_acc = model.evaluate(test_generator)
print(f"\n Test Accuracy: {test_acc*100:.2f}%")

# Step 7: Plot accuracy and loss
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Step 8: Define class labels
class_labels = list(train_generator.class_indices.keys())
print("Class labels:", class_labels)

# Step 9: Show 5 test images with predicted & actual labels
x_test_batch, y_test_batch = next(test_generator)

plt.figure(figsize=(15,4))
for i in range(5):
    img = x_test_batch[i]
    true_label = class_labels[np.argmax(y_test_batch[i])]
    
    pred = model.predict(img[np.newaxis, ...])
    predicted_label = class_labels[np.argmax(pred)]

    plt.subplot(1,5,i+1)
    plt.imshow(img)
    plt.title(f"Pred: {predicted_label}\nActual: {true_label}")
    plt.axis("off")

plt.show()

test_eval = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# True labels and class names (in correct order)
y_true = test_eval.classes
class_labels = list(test_eval.class_indices.keys())

# Predict over the entire test set
y_prob = model.predict(test_eval, verbose=0)
y_pred = np.argmax(y_prob, axis=1)

# Print report
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))


