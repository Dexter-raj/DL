# -----------------------------
# Import Libraries
# -----------------------------
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
import random

# -----------------------------
# Dataset Paths
# -----------------------------
train_dir = r"C:\Users\rajat\Downloads\food-101-tiny\train"
valid_dir = r"C:\Users\rajat\Downloads\food-101-tiny\valid"

# -----------------------------
# Data Preprocessing
# -----------------------------
train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=25,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)
valid_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(
    train_dir, target_size=(150,150), batch_size=32, class_mode='categorical'
)
valid_data = valid_gen.flow_from_directory(
    valid_dir, target_size=(150,150), batch_size=32, class_mode='categorical', shuffle=False
)

# -----------------------------
# Build CNN Model
# -----------------------------
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(len(train_data.class_indices), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# -----------------------------
# Train Model
# -----------------------------
history = model.fit(train_data, epochs=10, validation_data=valid_data)

# -----------------------------
# Evaluate Model
# -----------------------------
test_loss, test_acc = model.evaluate(valid_data)
print(f"\nâœ… Validation Accuracy: {test_acc*100:.2f}%")

# -----------------------------
# Plot Accuracy & Loss
# -----------------------------
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title('Model Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title('Model Loss')
plt.legend()
plt.show()

# -----------------------------
# Classification Report
# -----------------------------
y_true = valid_data.classes
class_labels = list(valid_data.class_indices.keys())
y_pred = np.argmax(model.predict(valid_data), axis=1)

print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))

# -----------------------------
# Confusion Matrix
# -----------------------------
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix - Food Classification')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# -----------------------------
# Show Few Predictions
# -----------------------------
x_batch, y_batch = next(valid_data)
plt.figure(figsize=(12,4))
for i in range(5):
    img = x_batch[i]
    true_label = class_labels[np.argmax(y_batch[i])]
    pred_label = class_labels[np.argmax(model.predict(img[np.newaxis, ...]))]
    plt.subplot(1,5,i+1)
    plt.imshow(img)
    plt.title(f"P: {pred_label}\nT: {true_label}")
    plt.axis('off')
plt.tight_layout()
plt.show()
